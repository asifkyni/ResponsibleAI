{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MetricFrame: Beyond Binary Classification\n",
    "=========================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of using\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} for\n",
    "tasks which go beyond simple binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "from fairlearn.metrics import MetricFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass & Nonscalar Results\n",
    "==============================\n",
    "\n",
    "Suppose we have a multiclass problem, with labels $\\in {0, 1, 2}$, and\n",
    "that we wish to generate confusion matrices for each subgroup identified\n",
    "by the sensitive feature $\\in { a, b, c, d}$. This is supported readily\n",
    "by `~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"},\n",
    "which does not require the result of a metric to be a scalar.\n",
    "\n",
    "First, let us generate some random input data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=96132)\n",
    "\n",
    "n_rows = 1000\n",
    "n_classes = 3\n",
    "n_sensitive_features = 4\n",
    "\n",
    "y_true = rng.integers(n_classes, size=n_rows)\n",
    "y_pred = rng.integers(n_classes, size=n_rows)\n",
    "\n",
    "temp = rng.integers(n_sensitive_features, size=n_rows)\n",
    "s_f = [chr(ord(\"a\") + x) for x in temp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `~sklearn.metrics.confusion_matrix`{.interpreted-text\n",
    "role=\"func\"}, we need to prebind the [labels]{.title-ref} argument,\n",
    "since it is possible that some of the subgroups will not contain all of\n",
    "the possible labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conf_mat = functools.partial(skm.confusion_matrix, labels=np.unique(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this now available, we can create our\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mf = MetricFrame(\n",
    "    metrics={\"conf_mat\": conf_mat}, y_true=y_true, y_pred=y_pred, sensitive_features=s_f\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can view the overall confusion matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conf_mat    [[101, 98, 126], [113, 97, 93], [113, 134, 125]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also the confusion matrices for each subgroup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf_mat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitive_feature_0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>[[28, 27, 24], [32, 17, 26], [26, 32, 36]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>[[27, 23, 25], [26, 32, 30], [36, 34, 28]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>[[20, 26, 34], [27, 29, 19], [23, 33, 30]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>[[26, 22, 43], [28, 19, 18], [28, 35, 31]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       conf_mat\n",
       "sensitive_feature_0                                            \n",
       "a                    [[28, 27, 24], [32, 17, 26], [26, 32, 36]]\n",
       "b                    [[27, 23, 25], [26, 32, 30], [36, 34, 28]]\n",
       "c                    [[20, 26, 34], [27, 29, 19], [23, 33, 30]]\n",
       "d                    [[26, 22, 43], [28, 19, 18], [28, 35, 31]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the other methods such as\n",
    "`~fairlearn.metrics.MetricFrame.group_min`{.interpreted-text\n",
    "role=\"meth\"} will not work, since operations such as \\'less than\\' are\n",
    "not well defined for matrices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric functions with different return types can also be mixed in a\n",
    "single `~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}.\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall values\n",
      "conf_mat    [[101, 98, 126], [113, 97, 93], [113, 134, 125]]\n",
      "recall                                              0.322308\n",
      "dtype: object\n",
      "Values by group\n",
      "                                                       conf_mat    recall\n",
      "sensitive_feature_0                                                      \n",
      "a                    [[28, 27, 24], [32, 17, 26], [26, 32, 36]]  0.321359\n",
      "b                    [[27, 23, 25], [26, 32, 30], [36, 34, 28]]  0.336450\n",
      "c                    [[20, 26, 34], [27, 29, 19], [23, 33, 30]]  0.328501\n",
      "d                    [[26, 22, 43], [28, 19, 18], [28, 35, 31]]  0.302603\n"
     ]
    }
   ],
   "source": [
    "recall = functools.partial(skm.recall_score, average=\"macro\")\n",
    "\n",
    "mf2 = MetricFrame(\n",
    "    metrics={\"conf_mat\": conf_mat, \"recall\": recall},\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=s_f,\n",
    ")\n",
    "\n",
    "print(\"Overall values\")\n",
    "print(mf2.overall)\n",
    "print(\"Values by group\")\n",
    "print(mf2.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-scalar Inputs\n",
    "=================\n",
    "\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} does\n",
    "not require its inputs to be scalars either. To demonstrate this, we\n",
    "will use an image recognition example (kindly supplied by Ferdane\n",
    "Bekmezci, Hamid Vaezi Joze and Samira Pouyanfar).\n",
    "\n",
    "Image recognition algorithms frequently construct a bounding box around\n",
    "regions where they have found their target features. For example, if an\n",
    "algorithm detects a face in an image, it will place a bounding box\n",
    "around it. These bounding boxes constitute [y\\_pred]{.title-ref} for\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}. The\n",
    "[y\\_true]{.title-ref} values then come from bounding boxes marked by\n",
    "human labellers.\n",
    "\n",
    "Bounding boxes are often compared using the \\'iou\\' metric. This\n",
    "computes the intersection and the union of the two bounding boxes, and\n",
    "returns the ratio of their areas. If the bounding boxes are identical,\n",
    "then the metric will be 1; if disjoint then it will be 0. A function to\n",
    "do this is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def bounding_box_iou(box_A_input, box_B_input):\n",
    "    # The inputs are array-likes in the form\n",
    "    # [x_0, y_0, delta_x,delta_y]\n",
    "    # where the deltas are positive\n",
    "\n",
    "    box_A = np.array(box_A_input)\n",
    "    box_B = np.array(box_B_input)\n",
    "\n",
    "    if box_A[2] < 0:\n",
    "        raise ValueError(\"Bad delta_x for box_A\")\n",
    "    if box_A[3] < 0:\n",
    "        raise ValueError(\"Bad delta y for box_A\")\n",
    "    if box_B[2] < 0:\n",
    "        raise ValueError(\"Bad delta x for box_B\")\n",
    "    if box_B[3] < 0:\n",
    "        raise ValueError(\"Bad delta y for box_B\")\n",
    "\n",
    "    # Convert deltas to coordinates\n",
    "    box_A[2:4] = box_A[0:2] + box_A[2:4]\n",
    "    box_B[2:4] = box_B[0:2] + box_B[2:4]\n",
    "\n",
    "    # Determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x_A = max(box_A[0], box_B[0])\n",
    "    y_A = max(box_A[1], box_B[1])\n",
    "    x_B = min(box_A[2], box_B[2])\n",
    "    y_B = min(box_A[3], box_B[3])\n",
    "\n",
    "    if (x_B < x_A) or (y_B < y_A):\n",
    "        return 0\n",
    "\n",
    "    # Compute the area of intersection rectangle\n",
    "    interArea = (x_B - x_A) * (y_B - y_A)\n",
    "\n",
    "    # Compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    box_A_area = (box_A[2] - box_A[0]) * (box_A[3] - box_A[1])\n",
    "    box_B_area = (box_B[2] - box_B[0]) * (box_B[3] - box_B[1])\n",
    "\n",
    "    # Compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(box_A_area + box_B_area - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a metric for two bounding boxes, but for\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} we need\n",
    "to compare two lists of bounding boxes. For the sake of simplicity, we\n",
    "will return the mean value of \\'iou\\' for the two lists, but this is by\n",
    "no means the only choice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def mean_iou(true_boxes, predicted_boxes):\n",
    "    if len(true_boxes) != len(predicted_boxes):\n",
    "        raise ValueError(\"Array size mismatch\")\n",
    "\n",
    "    all_iou = [\n",
    "        bounding_box_iou(y_true, y_pred)\n",
    "        for y_true, y_pred in zip(true_boxes, predicted_boxes)\n",
    "    ]\n",
    "\n",
    "    return np.mean(all_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate some input data, so first create a function to\n",
    "generate a single random bounding box:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_bounding_box(max_coord, max_delta, rng):\n",
    "    corner = max_coord * rng.random(size=2)\n",
    "    delta = max_delta * rng.random(size=2)\n",
    "\n",
    "    return np.concatenate((corner, delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this to create sample [y\\_true]{.title-ref} and\n",
    "[y\\_pred]{.title-ref} arrays of bounding boxes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def many_bounding_boxes(n_rows, max_coord, max_delta, rng):\n",
    "    return [generate_bounding_box(max_coord, max_delta, rng) for _ in range(n_rows)]\n",
    "\n",
    "\n",
    "true_bounding_boxes = many_bounding_boxes(n_rows, 5, 10, rng)\n",
    "pred_bounding_boxes = many_bounding_boxes(n_rows, 5, 10, rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use these in a\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"}:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall metric\n",
      "mean_iou    0.121063\n",
      "dtype: float64\n",
      "Metrics by group\n",
      "                     mean_iou\n",
      "sensitive_feature_0          \n",
      "a                    0.113238\n",
      "b                    0.129801\n",
      "c                    0.118929\n",
      "d                    0.121758\n"
     ]
    }
   ],
   "source": [
    "mf_bb = MetricFrame(\n",
    "    metrics={\"mean_iou\": mean_iou},\n",
    "    y_true=true_bounding_boxes,\n",
    "    y_pred=pred_bounding_boxes,\n",
    "    sensitive_features=s_f,\n",
    ")\n",
    "\n",
    "print(\"Overall metric\")\n",
    "print(mf_bb.overall)\n",
    "print(\"Metrics by group\")\n",
    "print(mf_bb.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual entries in the [y\\_true]{.title-ref} and\n",
    "[y\\_pred]{.title-ref} arrays can be arbitrarily complex. It is the\n",
    "metric functions which give meaning to them. Similarly,\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} does\n",
    "not impose restrictions on the return type. One can envisage an image\n",
    "recognition task where there are multiple detectable objects in each\n",
    "picture, and the image recognition algorithm produces multiple bounding\n",
    "boxes (not necessarily in a 1-to-1 mapping either). The output of such a\n",
    "scenario might well be a matrix of some description. Another case where\n",
    "both the input data and the metrics will be complex is natural language\n",
    "processing, where each row of the input could be an entire sentence,\n",
    "possibly with complex word embeddings included.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "==========\n",
    "\n",
    "This notebook has given some taste of the flexibility of\n",
    "`~fairlearn.metrics.MetricFrame`{.interpreted-text role=\"class\"} when it\n",
    "comes to inputs, outputs and metric functions. The input arrays can have\n",
    "elements of arbitrary types, and the return values from the metric\n",
    "functions can also be of any type (although methods such as\n",
    "`~fairlearn.metrics.MetricFrame.group_min`{.interpreted-text\n",
    "role=\"meth\"} may not work).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
