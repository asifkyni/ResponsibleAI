{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952787dd-5588-40a5-8240-e60909ed5940",
   "metadata": {},
   "source": [
    "# Understanding Model Bias vs. Data Bias\n",
    "\n",
    "**Data Bias**: Occurs when the training data is not representative of the real-world scenario, leading to skewed learning.\n",
    "**Model Bias**: Arises from the algorithms and methodologies used to train the model, causing systematic errors favoring one outcome over others.\n",
    "\n",
    "# Objective\n",
    "We'll identify and address model bias in the Wine dataset, focusing on techniques to mitigate bias resulting from class imbalance.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Load and preprocess the Wine dataset**.\n",
    "2. **Train a biased model** to demonstrate preference for the majority class.\n",
    "3. **Apply four different techniques** to mitigate this bias.\n",
    "4. **Evaluate and compare** results quantitatively and qualitatively.\n",
    "\n",
    "# Step 1: Import Libraries and Load Data\n",
    "We import necessary libraries and load the Wine dataset. The data is preprocessed, including standardization and conversion to PyTorch tensors.\n",
    "\n",
    "# Step 2: Define the Model\n",
    "A simple neural network model is defined using PyTorch for classifying the Wine dataset into three classes.\n",
    "\n",
    "# Step 3: Train the Biased Model\n",
    "We train the model using the training dataset, monitoring the loss over epochs to ensure the model is learning.\n",
    "\n",
    "# Step 4: Evaluate the Biased Model\n",
    "The model is evaluated using the test dataset. Accuracy, classification report, and confusion matrix are displayed to understand the model's performance.\n",
    "\n",
    "# Step 5: Mitigation Techniques\n",
    "We apply four different bias correction methods to the Wine dataset and retrain the model with each method:\n",
    "\n",
    "### Method 1: Reweighting\n",
    "Adjust the loss function to give different weights to classes based on their frequency in the training data.\n",
    "\n",
    "### Method 2: Oversampling\n",
    "Create more samples of the minority classes by duplicating existing samples, ensuring equal representation of each class.\n",
    "\n",
    "### Method 3: Undersampling\n",
    "Reduce the number of samples from the majority class to match the minority class, balancing class distribution.\n",
    "\n",
    "### Method 4: Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "Generate synthetic samples for the minority classes by interpolating between existing samples, balancing class distribution while preserving diversity.\n",
    "\n",
    "# Results\n",
    "For each method, retrain the model and evaluate its performance on the test dataset. Display accuracy and classification report to compare the effectiveness of each bias correction method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee25a9a-82a0-409e-8d37-e8861fb933fd",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries and Load Data\n",
    "We import necessary libraries and load the Wine dataset. The data is preprocessed, including standardization and conversion to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c5d3cea-e3e4-4f56-b2e3-f4152b2a590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Load Wine dataset\n",
    "# url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "# column_names = [\n",
    "#     'Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
    "#     'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "#     'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'\n",
    "# ]\n",
    "# wine_data = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# # Split data into features and target\n",
    "# X = wine_data.drop('Class', axis=1).values\n",
    "# y = wine_data['Class'].values - 1  # Classes need to be zero-indexed for PyTorch\n",
    "\n",
    "# # Split into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # Convert to PyTorch tensors\n",
    "# X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "# y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "# X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# # Create DataLoader\n",
    "# train_dataset = TensorDataset(X_train, y_train)\n",
    "# test_dataset = TensorDataset(X_test, y_test)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90fc553-1335-4677-95e3-5c922101bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'is_red']\n",
      "Data processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# # Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define URLs for the datasets\n",
    "red_wine_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "white_wine_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "# Define local paths for saving the datasets\n",
    "local_red_wine_path = \"./data/datasets/winequality-red.csv\"\n",
    "local_white_wine_path = \"./data/datasets/winequality-white.csv\"\n",
    "\n",
    "# Create directories if they do not exist\n",
    "os.makedirs(os.path.dirname(local_red_wine_path), exist_ok=True)\n",
    "\n",
    "# Download the datasets\n",
    "urllib.request.urlretrieve(red_wine_url, local_red_wine_path)\n",
    "urllib.request.urlretrieve(white_wine_url, local_white_wine_path)\n",
    "\n",
    "# Define column names\n",
    "column_names = [\n",
    "    'fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides',\n",
    "    'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality'\n",
    "]\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"WineDataProcessing\").getOrCreate()\n",
    "\n",
    "# Read the CSV files using Spark with the correct delimiter\n",
    "red_wine_data = spark.read.csv(local_red_wine_path, header=True, sep=';', inferSchema=True)\n",
    "white_wine_data = spark.read.csv(local_white_wine_path, header=True, sep=';', inferSchema=True)\n",
    "\n",
    "# Convert Spark DataFrames to Pandas DataFrames\n",
    "red_wine_pd = red_wine_data.toPandas()\n",
    "white_wine_pd = white_wine_data.toPandas()\n",
    "\n",
    "# Add 'is_red' column\n",
    "red_wine_pd['is_red'] = 1\n",
    "white_wine_pd['is_red'] = 0\n",
    "\n",
    "# Concatenate the datasets\n",
    "wine_data = pd.concat([red_wine_pd, white_wine_pd], axis=0)\n",
    "\n",
    "# Rename columns to replace spaces with underscores (if necessary)\n",
    "wine_data.columns = wine_data.columns.str.replace('\"', '').str.replace(';', '').str.replace(' ', '_')\n",
    "\n",
    "# Check column names\n",
    "print(\"Columns in the dataset:\", wine_data.columns.tolist())\n",
    "\n",
    "# Ensure the 'quality' column exists in the dataset\n",
    "if 'quality' not in wine_data.columns:\n",
    "    raise KeyError(\"'quality' column not found in dataset\")\n",
    "\n",
    "# Split data into features and target\n",
    "X = wine_data.drop('quality', axis=1).values\n",
    "y = wine_data['quality'].values - 1  # Classes need to be zero-indexed for PyTorch\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(\"Data processing completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9820551-5e1b-4875-bcd3-d463a5c34c0d",
   "metadata": {},
   "source": [
    "# Step 2: Define the Model\n",
    "A simple neural network model is defined using PyTorch for classifying the Wine dataset into three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a23c7d5-ef8f-4319-9810-cb504c28c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class WineClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WineClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, criterion and optimizer\n",
    "model = WineClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d27c75-3e0a-44bc-8486-900454d62d47",
   "metadata": {},
   "source": [
    "# Step 3: Train the Biased Model\n",
    "We train the model using the training dataset, monitoring the loss over epochs to ensure the model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a3ce01-2d3a-45ed-b95a-db8a5b6f8b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 12])\n",
      "Label shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(f'Input shape: {inputs.shape}')\n",
    "    print(f'Label shape: {labels.shape}')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78333559-75b7-48c7-b2a5-9a9235dfea6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x12 and 13x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mWineClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x12 and 13x50)"
     ]
    }
   ],
   "source": [
    "# # Training function\n",
    "# def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         running_loss = 0.0\n",
    "#         for inputs, labels in train_loader:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#         epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#         print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_loader, criterion, optimizer, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a097246-192d-4360-afe7-09644795319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.5746\n",
      "Epoch 2/50, Loss: 1.2460\n",
      "Epoch 3/50, Loss: 1.1789\n",
      "Epoch 4/50, Loss: 1.1463\n",
      "Epoch 5/50, Loss: 1.1242\n",
      "Epoch 6/50, Loss: 1.1098\n",
      "Epoch 7/50, Loss: 1.0981\n",
      "Epoch 8/50, Loss: 1.0905\n",
      "Epoch 9/50, Loss: 1.0837\n",
      "Epoch 10/50, Loss: 1.0782\n",
      "Epoch 11/50, Loss: 1.0736\n",
      "Epoch 12/50, Loss: 1.0692\n",
      "Epoch 13/50, Loss: 1.0663\n",
      "Epoch 14/50, Loss: 1.0620\n",
      "Epoch 15/50, Loss: 1.0601\n",
      "Epoch 16/50, Loss: 1.0574\n",
      "Epoch 17/50, Loss: 1.0542\n",
      "Epoch 18/50, Loss: 1.0510\n",
      "Epoch 19/50, Loss: 1.0502\n",
      "Epoch 20/50, Loss: 1.0478\n",
      "Epoch 21/50, Loss: 1.0458\n",
      "Epoch 22/50, Loss: 1.0435\n",
      "Epoch 23/50, Loss: 1.0419\n",
      "Epoch 24/50, Loss: 1.0406\n",
      "Epoch 25/50, Loss: 1.0390\n",
      "Epoch 26/50, Loss: 1.0372\n",
      "Epoch 27/50, Loss: 1.0356\n",
      "Epoch 28/50, Loss: 1.0346\n",
      "Epoch 29/50, Loss: 1.0323\n",
      "Epoch 30/50, Loss: 1.0315\n",
      "Epoch 31/50, Loss: 1.0301\n",
      "Epoch 32/50, Loss: 1.0287\n",
      "Epoch 33/50, Loss: 1.0272\n",
      "Epoch 34/50, Loss: 1.0256\n",
      "Epoch 35/50, Loss: 1.0243\n",
      "Epoch 36/50, Loss: 1.0224\n",
      "Epoch 37/50, Loss: 1.0223\n",
      "Epoch 38/50, Loss: 1.0209\n",
      "Epoch 39/50, Loss: 1.0203\n",
      "Epoch 40/50, Loss: 1.0191\n",
      "Epoch 41/50, Loss: 1.0178\n",
      "Epoch 42/50, Loss: 1.0157\n",
      "Epoch 43/50, Loss: 1.0147\n",
      "Epoch 44/50, Loss: 1.0140\n",
      "Epoch 45/50, Loss: 1.0133\n",
      "Epoch 46/50, Loss: 1.0119\n",
      "Epoch 47/50, Loss: 1.0104\n",
      "Epoch 48/50, Loss: 1.0093\n",
      "Epoch 49/50, Loss: 1.0086\n",
      "Epoch 50/50, Loss: 1.0084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define input size, hidden size, and output size\n",
    "input_size = 12  # Number of features\n",
    "hidden_size = 50  # Number of neurons in hidden layer\n",
    "output_size = 10  # Number of classes (adjust as needed)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163a49f-bb19-4a61-aa86-882ec4d830b8",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate the Biased Model\n",
    "The model is evaluated using the test dataset. Accuracy, classification report, and confusion matrix are displayed to understand the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96dc0d1-33fa-4b7e-9853-682c874b739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5553846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.50      0.07      0.13        69\n",
      "           4       0.57      0.67      0.62       613\n",
      "           5       0.56      0.64      0.60       894\n",
      "           6       0.47      0.30      0.37       315\n",
      "           7       0.00      0.00      0.00        49\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56      1950\n",
      "   macro avg       0.30      0.24      0.24      1950\n",
      "weighted avg       0.53      0.56      0.53      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.numpy())\n",
    "            actuals.extend(labels.numpy())\n",
    "    return predictions, actuals\n",
    "\n",
    "# Evaluate the model\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "\n",
    "# Display results\n",
    "print(\"Accuracy:\", accuracy_score(actuals, predictions))\n",
    "print(classification_report(actuals, predictions))\n",
    "\n",
    "# Plotting confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(actuals, predictions)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74c923-9d3d-4908-94ac-b9a8f81eaa44",
   "metadata": {},
   "source": [
    "# Step 5: Mitigation Techniques\n",
    "We apply four different bias correction methods to the Wine dataset and retrain the model with each method:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd9553-df0e-4a4d-8eaf-54d76b0a671c",
   "metadata": {},
   "source": [
    "### Method 1: Reweighting\n",
    "Adjust the loss function to give different weights to classes based on their frequency in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f7d466f-ef62-45aa-b01d-d468c9d2c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214291/1265665993.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  class_weights = total_samples / (len(np.unique(y_train)) * class_counts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.1343\n",
      "Epoch 2/50, Loss: 1.1408\n",
      "Epoch 3/50, Loss: 1.1237\n",
      "Epoch 4/50, Loss: 1.0737\n",
      "Epoch 5/50, Loss: 1.0929\n",
      "Epoch 6/50, Loss: 1.0979\n",
      "Epoch 7/50, Loss: 1.0904\n",
      "Epoch 8/50, Loss: 1.1130\n",
      "Epoch 9/50, Loss: 1.0591\n",
      "Epoch 10/50, Loss: 1.0602\n",
      "Epoch 11/50, Loss: 1.0934\n",
      "Epoch 12/50, Loss: 1.0673\n",
      "Epoch 13/50, Loss: 1.0915\n",
      "Epoch 14/50, Loss: 1.0604\n",
      "Epoch 15/50, Loss: 1.0521\n",
      "Epoch 16/50, Loss: 1.0532\n",
      "Epoch 17/50, Loss: 1.0462\n",
      "Epoch 18/50, Loss: 1.0534\n",
      "Epoch 19/50, Loss: 1.0398\n",
      "Epoch 20/50, Loss: 1.0585\n",
      "Epoch 21/50, Loss: 1.0240\n",
      "Epoch 22/50, Loss: 1.0178\n",
      "Epoch 23/50, Loss: 1.0573\n",
      "Epoch 24/50, Loss: 1.0669\n",
      "Epoch 25/50, Loss: 1.0403\n",
      "Epoch 26/50, Loss: 1.0020\n",
      "Epoch 27/50, Loss: 1.0291\n",
      "Epoch 28/50, Loss: 1.0374\n",
      "Epoch 29/50, Loss: 1.0385\n",
      "Epoch 30/50, Loss: 1.0138\n",
      "Epoch 31/50, Loss: 1.0133\n",
      "Epoch 32/50, Loss: 1.0021\n",
      "Epoch 33/50, Loss: 1.0059\n",
      "Epoch 34/50, Loss: 1.0152\n",
      "Epoch 35/50, Loss: 1.0268\n",
      "Epoch 36/50, Loss: 1.0067\n",
      "Epoch 37/50, Loss: 0.9871\n",
      "Epoch 38/50, Loss: 1.0205\n",
      "Epoch 39/50, Loss: 1.0099\n",
      "Epoch 40/50, Loss: 0.9973\n",
      "Epoch 41/50, Loss: 1.0285\n",
      "Epoch 42/50, Loss: 0.9995\n",
      "Epoch 43/50, Loss: 1.0133\n",
      "Epoch 44/50, Loss: 1.0121\n",
      "Epoch 45/50, Loss: 1.0043\n",
      "Epoch 46/50, Loss: 1.0127\n",
      "Epoch 47/50, Loss: 0.9963\n",
      "Epoch 48/50, Loss: 1.0084\n",
      "Epoch 49/50, Loss: 1.0395\n",
      "Epoch 50/50, Loss: 0.9942\n",
      "Reweighting Method Accuracy: 0.5656410256410257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.40      0.22      0.29         9\n",
      "           3       0.45      0.13      0.20        69\n",
      "           4       0.59      0.62      0.61       613\n",
      "           5       0.56      0.72      0.63       894\n",
      "           6       0.56      0.21      0.31       315\n",
      "           7       0.00      0.00      0.00        49\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.57      1950\n",
      "   macro avg       0.37      0.27      0.29      1950\n",
      "weighted avg       0.55      0.57      0.54      1950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Reweighting method\n",
    "class ReweightingLoss(nn.Module):\n",
    "    def __init__(self, base_criterion, weights):\n",
    "        super(ReweightingLoss, self).__init__()\n",
    "        self.base_criterion = base_criterion\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        loss = self.base_criterion(inputs, targets)\n",
    "        weight = self.weights[targets]\n",
    "        loss = loss * weight\n",
    "        return loss.mean()\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = np.bincount(y_train.numpy())\n",
    "total_samples = len(y_train)\n",
    "class_weights = total_samples / (len(np.unique(y_train)) * class_counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Apply reweighting\n",
    "reweighted_criterion = ReweightingLoss(criterion, class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, train_loader, reweighted_criterion, optimizer, epochs=50)\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(\"Reweighting Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f96891-b3fd-4f01-80c8-cdc9f39aab01",
   "metadata": {},
   "source": [
    "### Method 2: Oversampling\n",
    "Create more samples of the minority classes by duplicating existing samples, ensuring equal representation of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b65cd8-6bd7-4eef-b7f8-32f35ce9a254",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x12 and 13x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m WineClassifier()\n\u001b[1;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_oversample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m predictions, actuals \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOversampling Method Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(actuals, predictions))\n",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     34\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     37\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mWineClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x12 and 13x50)"
     ]
    }
   ],
   "source": [
    "# # Oversampling method\n",
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# # Calculate sample weights\n",
    "# sample_weights = [class_weights[label] for label in y_train]\n",
    "# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# # Create DataLoader with oversampling\n",
    "# train_loader_oversample = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "\n",
    "# # Train with oversampling\n",
    "# model = WineClassifier()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# train_model(model, train_loader_oversample, criterion, optimizer, epochs=50)\n",
    "# predictions, actuals = evaluate_model(model, test_loader)\n",
    "# print(\"Oversampling Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "# print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "177a07c5-625a-4073-a446-65a23c0207ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.7796\n",
      "Epoch 2/50, Loss: 1.3733\n",
      "Epoch 3/50, Loss: 1.2501\n",
      "Epoch 4/50, Loss: 1.1596\n",
      "Epoch 5/50, Loss: 1.0976\n",
      "Epoch 6/50, Loss: 1.0517\n",
      "Epoch 7/50, Loss: 1.0563\n",
      "Epoch 8/50, Loss: 0.9925\n",
      "Epoch 9/50, Loss: 0.9968\n",
      "Epoch 10/50, Loss: 0.9535\n",
      "Epoch 11/50, Loss: 0.9401\n",
      "Epoch 12/50, Loss: 0.9205\n",
      "Epoch 13/50, Loss: 0.9232\n",
      "Epoch 14/50, Loss: 0.8923\n",
      "Epoch 15/50, Loss: 0.9017\n",
      "Epoch 16/50, Loss: 0.8985\n",
      "Epoch 17/50, Loss: 0.8660\n",
      "Epoch 18/50, Loss: 0.8507\n",
      "Epoch 19/50, Loss: 0.8506\n",
      "Epoch 20/50, Loss: 0.8535\n",
      "Epoch 21/50, Loss: 0.8337\n",
      "Epoch 22/50, Loss: 0.8234\n",
      "Epoch 23/50, Loss: 0.8270\n",
      "Epoch 24/50, Loss: 0.8232\n",
      "Epoch 25/50, Loss: 0.8212\n",
      "Epoch 26/50, Loss: 0.8451\n",
      "Epoch 27/50, Loss: 0.8265\n",
      "Epoch 28/50, Loss: 0.8062\n",
      "Epoch 29/50, Loss: 0.7950\n",
      "Epoch 30/50, Loss: 0.7966\n",
      "Epoch 31/50, Loss: 0.7870\n",
      "Epoch 32/50, Loss: 0.8119\n",
      "Epoch 33/50, Loss: 0.7937\n",
      "Epoch 34/50, Loss: 0.7828\n",
      "Epoch 35/50, Loss: 0.7863\n",
      "Epoch 36/50, Loss: 0.7769\n",
      "Epoch 37/50, Loss: 0.7784\n",
      "Epoch 38/50, Loss: 0.7902\n",
      "Epoch 39/50, Loss: 0.8061\n",
      "Epoch 40/50, Loss: 0.7678\n",
      "Epoch 41/50, Loss: 0.7645\n",
      "Epoch 42/50, Loss: 0.7574\n",
      "Epoch 43/50, Loss: 0.7650\n",
      "Epoch 44/50, Loss: 0.7719\n",
      "Epoch 45/50, Loss: 0.7584\n",
      "Epoch 46/50, Loss: 0.7407\n",
      "Epoch 47/50, Loss: 0.7701\n",
      "Epoch 48/50, Loss: 0.7619\n",
      "Epoch 49/50, Loss: 0.7504\n",
      "Epoch 50/50, Loss: 0.7388\n",
      "Oversampling Method Accuracy: 0.39794871794871794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.04      0.22      0.07         9\n",
      "           3       0.11      0.48      0.18        69\n",
      "           4       0.56      0.46      0.51       613\n",
      "           5       0.59      0.37      0.46       894\n",
      "           6       0.37      0.30      0.33       315\n",
      "           7       0.10      0.59      0.18        49\n",
      "           8       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.40      1950\n",
      "   macro avg       0.29      0.49      0.30      1950\n",
      "weighted avg       0.51      0.40      0.43      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "\n",
    "# Define the model\n",
    "class WineClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WineClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = 12  # Update this if needed based on your actual data\n",
    "hidden_size = 50\n",
    "output_size = 10  # Adjust this based on the number of classes in your dataset\n",
    "\n",
    "# Instantiate the model\n",
    "model = WineClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Calculate class weights\n",
    "class_counts = Counter(y_train.numpy())  # Convert y_train to numpy array for Counter\n",
    "total_samples = len(y_train)\n",
    "class_weights = {cls: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\n",
    "\n",
    "# Generate sample weights based on class weights\n",
    "sample_weights = [class_weights[int(label)] for label in y_train.numpy()]  # Convert tensor labels to integers\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Create DataLoader with oversampling\n",
    "train_loader_oversample = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "\n",
    "# Train with oversampling\n",
    "train_model(model, train_loader_oversample, criterion, optimizer, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(\"Oversampling Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39753a9f-187d-45fe-8c36-d527ae518eed",
   "metadata": {},
   "source": [
    "### Method 3: Undersampling\n",
    "Reduce the number of samples from the majority class to match the minority class, balancing class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d239247-ea2a-4014-b57d-7ccfb17f5da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'input_size', 'hidden_size', and 'output_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m train_loader_undersample \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset_undersample, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train with undersampling\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWineClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     17\u001b[0m train_model(model, train_loader_undersample, criterion, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'input_size', 'hidden_size', and 'output_size'"
     ]
    }
   ],
   "source": [
    "# # Undersampling method\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # Apply undersampling\n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# # Convert back to PyTorch tensors\n",
    "# X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "# y_resampled = torch.tensor(y_resampled, dtype=torch.long)\n",
    "# train_dataset_undersample = TensorDataset(X_resampled, y_resampled)\n",
    "# train_loader_undersample = DataLoader(train_dataset_undersample, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Train with undersampling\n",
    "# model = WineClassifier()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# train_model(model, train_loader_undersample, criterion, optimizer, epochs=50)\n",
    "# predictions, actuals = evaluate_model(model, test_loader)\n",
    "# print(\"Undersampling Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "# print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0d3f81a-0ca1-4d65-aa3c-7693eeac18f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 2.3645\n",
      "Epoch 2/50, Loss: 2.3262\n",
      "Epoch 3/50, Loss: 2.2920\n",
      "Epoch 4/50, Loss: 2.2587\n",
      "Epoch 5/50, Loss: 2.2246\n",
      "Epoch 6/50, Loss: 2.1923\n",
      "Epoch 7/50, Loss: 2.1620\n",
      "Epoch 8/50, Loss: 2.1311\n",
      "Epoch 9/50, Loss: 2.1001\n",
      "Epoch 10/50, Loss: 2.0686\n",
      "Epoch 11/50, Loss: 2.0417\n",
      "Epoch 12/50, Loss: 2.0130\n",
      "Epoch 13/50, Loss: 1.9848\n",
      "Epoch 14/50, Loss: 1.9581\n",
      "Epoch 15/50, Loss: 1.9308\n",
      "Epoch 16/50, Loss: 1.9040\n",
      "Epoch 17/50, Loss: 1.8775\n",
      "Epoch 18/50, Loss: 1.8524\n",
      "Epoch 19/50, Loss: 1.8265\n",
      "Epoch 20/50, Loss: 1.8047\n",
      "Epoch 21/50, Loss: 1.7785\n",
      "Epoch 22/50, Loss: 1.7550\n",
      "Epoch 23/50, Loss: 1.7318\n",
      "Epoch 24/50, Loss: 1.7080\n",
      "Epoch 25/50, Loss: 1.6843\n",
      "Epoch 26/50, Loss: 1.6648\n",
      "Epoch 27/50, Loss: 1.6418\n",
      "Epoch 28/50, Loss: 1.6204\n",
      "Epoch 29/50, Loss: 1.6001\n",
      "Epoch 30/50, Loss: 1.5797\n",
      "Epoch 31/50, Loss: 1.5582\n",
      "Epoch 32/50, Loss: 1.5390\n",
      "Epoch 33/50, Loss: 1.5193\n",
      "Epoch 34/50, Loss: 1.4993\n",
      "Epoch 35/50, Loss: 1.4819\n",
      "Epoch 36/50, Loss: 1.4616\n",
      "Epoch 37/50, Loss: 1.4436\n",
      "Epoch 38/50, Loss: 1.4259\n",
      "Epoch 39/50, Loss: 1.4087\n",
      "Epoch 40/50, Loss: 1.3904\n",
      "Epoch 41/50, Loss: 1.3728\n",
      "Epoch 42/50, Loss: 1.3557\n",
      "Epoch 43/50, Loss: 1.3396\n",
      "Epoch 44/50, Loss: 1.3234\n",
      "Epoch 45/50, Loss: 1.3072\n",
      "Epoch 46/50, Loss: 1.2910\n",
      "Epoch 47/50, Loss: 1.2750\n",
      "Epoch 48/50, Loss: 1.2600\n",
      "Epoch 49/50, Loss: 1.2448\n",
      "Epoch 50/50, Loss: 1.2297\n",
      "Undersampling Method Accuracy: 0.19641025641025642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.01      0.22      0.01         9\n",
      "           3       0.11      0.29      0.16        69\n",
      "           4       0.52      0.38      0.44       613\n",
      "           5       0.53      0.09      0.15       894\n",
      "           6       0.22      0.12      0.16       315\n",
      "           7       0.04      0.20      0.06        49\n",
      "           8       0.00      1.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20      1950\n",
      "   macro avg       0.20      0.33      0.14      1950\n",
      "weighted avg       0.45      0.20      0.24      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the model\n",
    "class WineClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WineClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize parameters\n",
    "input_size = 12  # Number of features\n",
    "hidden_size = 50\n",
    "output_size = 10  # Number of classes\n",
    "\n",
    "# Instantiate the model with the correct parameters\n",
    "model = WineClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Apply undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# Convert back to PyTorch tensors\n",
    "X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "y_resampled = torch.tensor(y_resampled, dtype=torch.long)\n",
    "train_dataset_undersample = TensorDataset(X_resampled, y_resampled)\n",
    "train_loader_undersample = DataLoader(train_dataset_undersample, batch_size=16, shuffle=True)\n",
    "\n",
    "# Train with undersampling\n",
    "train_model(model, train_loader_undersample, criterion, optimizer, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(\"Undersampling Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849d0df-159e-40dd-abb8-b8d1eb1ca5bd",
   "metadata": {},
   "source": [
    "### Method 4: Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "Generate synthetic samples for the minority classes by interpolating between existing samples, balancing class distribution while preserving diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5bf0316-8151-4171-9ad9-9342c2673ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply SMOTE\u001b[39;00m\n\u001b[1;32m      5\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43msmote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert back to PyTorch tensors\u001b[39;00m\n\u001b[1;32m      9\u001b[0m X_resampled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_resampled, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/imblearn/base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    116\u001b[0m )\n\u001b[1;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/imblearn/over_sampling/_smote/base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[1;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/neighbors/_base.py:808\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    809\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected n_neighbors <= n_samples, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but n_samples = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, n_neighbors = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_samples_fit, n_neighbors)\n\u001b[1;32m    811\u001b[0m     )\n\u001b[1;32m    813\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    814\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 4, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "# # SMOTE method\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# # Apply SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# # Convert back to PyTorch tensors\n",
    "# X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "# y_resampled = torch.tensor(y_resampled, dtype=torch.long)\n",
    "# train_dataset_smote = TensorDataset(X_resampled, y_resampled)\n",
    "# train_loader_smote = DataLoader(train_dataset_smote, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Train with SMOTE\n",
    "# model = WineClassifier()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# train_model(model, train_loader_smote, criterion, optimizer, epochs=50)\n",
    "# predictions, actuals = evaluate_model(model, test_loader)\n",
    "# print(\"SMOTE Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "# print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0656a3b-def3-4d63-838a-581be9fc90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.4540\n",
      "Epoch 2/50, Loss: 1.0964\n",
      "Epoch 3/50, Loss: 1.0011\n",
      "Epoch 4/50, Loss: 0.9412\n",
      "Epoch 5/50, Loss: 0.8977\n",
      "Epoch 6/50, Loss: 0.8636\n",
      "Epoch 7/50, Loss: 0.8386\n",
      "Epoch 8/50, Loss: 0.8175\n",
      "Epoch 9/50, Loss: 0.7983\n",
      "Epoch 10/50, Loss: 0.7828\n",
      "Epoch 11/50, Loss: 0.7699\n",
      "Epoch 12/50, Loss: 0.7581\n",
      "Epoch 13/50, Loss: 0.7496\n",
      "Epoch 14/50, Loss: 0.7396\n",
      "Epoch 15/50, Loss: 0.7308\n",
      "Epoch 16/50, Loss: 0.7227\n",
      "Epoch 17/50, Loss: 0.7144\n",
      "Epoch 18/50, Loss: 0.7085\n",
      "Epoch 19/50, Loss: 0.7014\n",
      "Epoch 20/50, Loss: 0.6959\n",
      "Epoch 21/50, Loss: 0.6896\n",
      "Epoch 22/50, Loss: 0.6846\n",
      "Epoch 23/50, Loss: 0.6792\n",
      "Epoch 24/50, Loss: 0.6757\n",
      "Epoch 25/50, Loss: 0.6697\n",
      "Epoch 26/50, Loss: 0.6651\n",
      "Epoch 27/50, Loss: 0.6620\n",
      "Epoch 28/50, Loss: 0.6583\n",
      "Epoch 29/50, Loss: 0.6536\n",
      "Epoch 30/50, Loss: 0.6506\n",
      "Epoch 31/50, Loss: 0.6465\n",
      "Epoch 32/50, Loss: 0.6438\n",
      "Epoch 33/50, Loss: 0.6389\n",
      "Epoch 34/50, Loss: 0.6364\n",
      "Epoch 35/50, Loss: 0.6342\n",
      "Epoch 36/50, Loss: 0.6301\n",
      "Epoch 37/50, Loss: 0.6264\n",
      "Epoch 38/50, Loss: 0.6244\n",
      "Epoch 39/50, Loss: 0.6216\n",
      "Epoch 40/50, Loss: 0.6190\n",
      "Epoch 41/50, Loss: 0.6159\n",
      "Epoch 42/50, Loss: 0.6132\n",
      "Epoch 43/50, Loss: 0.6129\n",
      "Epoch 44/50, Loss: 0.6098\n",
      "Epoch 45/50, Loss: 0.6062\n",
      "Epoch 46/50, Loss: 0.6052\n",
      "Epoch 47/50, Loss: 0.6026\n",
      "Epoch 48/50, Loss: 0.5997\n",
      "Epoch 49/50, Loss: 0.5974\n",
      "Epoch 50/50, Loss: 0.5968\n",
      "SMOTE Method Accuracy: 0.4307692307692308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.08      0.22      0.11         9\n",
      "           3       0.12      0.42      0.19        69\n",
      "           4       0.56      0.47      0.51       613\n",
      "           5       0.59      0.37      0.46       894\n",
      "           6       0.39      0.51      0.44       315\n",
      "           7       0.12      0.47      0.19        49\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43      1950\n",
      "   macro avg       0.27      0.35      0.27      1950\n",
      "weighted avg       0.52      0.43      0.46      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model\n",
    "class WineClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WineClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize parameters\n",
    "input_size = 12  # Number of features\n",
    "hidden_size = 50\n",
    "output_size = 10  # Number of classes\n",
    "\n",
    "# Instantiate the model with the correct parameters\n",
    "model = WineClassifier(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)  # Set k_neighbors to a value  the minority class size\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train.numpy(), y_train.numpy())\n",
    "\n",
    "# Convert back to PyTorch tensors\n",
    "X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "y_resampled = torch.tensor(y_resampled, dtype=torch.long)\n",
    "train_dataset_smote = TensorDataset(X_resampled, y_resampled)\n",
    "train_loader_smote = DataLoader(train_dataset_smote, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the training function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    return all_preds, all_labels\n",
    "\n",
    "# Train with SMOTE\n",
    "train_model(model, train_loader_smote, criterion, optimizer, epochs=50)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions, actuals = evaluate_model(model, test_loader)\n",
    "print(\"SMOTE Method Accuracy:\", accuracy_score(actuals, predictions))\n",
    "print(classification_report(actuals, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c38f08-6aec-460c-99ba-f41da1a1d3ab",
   "metadata": {},
   "source": [
    "## Results\n",
    "For each method, we retrain the model and evaluate its performance on the test dataset. We display the accuracy and classification report to compare the effectiveness of each bias correction method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fbebd-401b-4c95-8401-1801380b5ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8195332c-4803-402d-bf9b-df3ef1fa0760",
   "metadata": {},
   "source": [
    "# Understanding Model Bias vs. Data Bias\n",
    "\n",
    "**Data Bias**: Occurs when the training data is not representative of the real-world scenario, leading to skewed learning.\n",
    "**Model Bias**: Arises from the algorithms and methodologies used to train the model, causing systematic errors favoring one outcome over others.\n",
    "\n",
    "# Objective\n",
    "We'll identify and address model bias in the Wine dataset, focusing on techniques to mitigate bias resulting from class imbalance.\n",
    "\n",
    "# Steps\n",
    "\n",
    "1. **Load and preprocess the Wine dataset**.\n",
    "2. **Train a biased model** to demonstrate preference for the majority class.\n",
    "3. **Apply four different techniques** to mitigate this bias.\n",
    "4. **Evaluate and compare** results quantitatively and qualitatively.\n",
    "\n",
    "# Step 1: Import Libraries and Load Data\n",
    "We import necessary libraries and load the Wine dataset. The data is preprocessed, including standardization and conversion to PyTorch tensors.\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Train the Biased Model\n",
    "We train the model using the training dataset, monitoring the loss over epochs to ensure the model is learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Method 3: Undersampling\n",
    "Reduce the number of samples from the majority class to match the minority class, balancing class distribution.\n",
    "\n",
    "### Method 4: Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "Generate synthetic samples for the minority classes by interpolating between existing samples, balancing class distribution while preserving diversity.\n",
    "\n",
    "# Results\n",
    "For each method, retrain the model and evaluate its performance on the test dataset. Display accuracy and classification report to compare the effectiveness of each bias correction method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e6dce-7e57-4475-9f8e-3fee5d4bdb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa21e60-0512-4f59-a2f3-bdab5a429aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ee0d8-715e-4e37-afff-0f26085333c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
