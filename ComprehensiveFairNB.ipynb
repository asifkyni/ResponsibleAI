{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b2172d-d287-40e4-9833-fb054e53d45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fairlearn in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: matplotlib in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from fairlearn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from fairlearn) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from fairlearn) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from fairlearn) (1.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (1.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fairlearn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165407ca-fb54-48e5-962a-09650dfa37bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Male      32650\n",
       "Female    16192\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.datasets import fetch_adult\n",
    "data = fetch_adult(as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8975d-7b80-43e9-81ef-4038e4f15bf6",
   "metadata": {},
   "source": [
    "## Model Bias Detection and Mitigation using Fairlearn\n",
    "In this example, we'll use the Adult dataset from the UCI Machine Learning Repository to demonstrate how to detect and mitigate model bias. We'll explore bias based on the 'sex' attribute and apply different techniques to address any detected bias. We'll use Fairlearn and other tools for bias detection and mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd9b50e6-2299-4645-94be-d464711d5177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Male      32650\n",
      "Female    16192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.datasets import fetch_adult\n",
    "\n",
    "# Load the dataset\n",
    "data = fetch_adult(as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "\n",
    "# Check the distribution of the sensitive attribute\n",
    "print(sex.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fd5af-eee2-49d1-8940-5d4e07218430",
   "metadata": {},
   "source": [
    "### Step 1: Load and Prepare the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef1b711c-d522-41a8-8fcc-2a30c1aa4f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Male      32650\n",
      "Female    16192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.datasets import fetch_adult\n",
    "\n",
    "# Load the dataset\n",
    "data = fetch_adult(as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "\n",
    "# Check the distribution of the sensitive attribute\n",
    "print(sex.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecabe50b-5d4d-45bd-b54c-379b5a79d6b6",
   "metadata": {},
   "source": [
    "### Step 2: Train Initial Model\n",
    "\n",
    "We train an initial Logistic Regression model to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f0767f5-12d9-4076-9c8a-ab406543157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796901658363475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     11147\n",
      "           1       0.71      0.25      0.37      3506\n",
      "\n",
      "    accuracy                           0.80     14653\n",
      "   macro avg       0.76      0.61      0.63     14653\n",
      "weighted avg       0.78      0.80      0.76     14653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test, sex_train, sex_test = train_test_split(X, y_true, sex, test_size=0.3, random_state=0, stratify=y_true)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca15d1d-e82b-4a1c-900d-1a238b98ff97",
   "metadata": {},
   "source": [
    "### Step 3: Detect Bias using Fairlearn\n",
    "\n",
    "We'll check for fairness issues using metrics such as demographic parity and equalized odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc892be-7b0e-4437-85d5-f005b5dfd8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "demographic_parity_difference() missing 1 required keyword-only argument: 'sensitive_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m y_true_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m sex_test \u001b[38;5;241m=\u001b[39m sex_test\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m metric_frame \u001b[38;5;241m=\u001b[39m \u001b[43mMetricFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msex_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(metric_frame\u001b[38;5;241m.\u001b[39mby_group)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_metric_frame.py:280\u001b[0m, in \u001b[0;36mMetricFrame.__init__\u001b[0;34m(self, metrics, y_true, y_pred, sensitive_features, control_features, sample_params, n_boot, ci_quantiles, random_state)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Create the basic results\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDisaggregatedResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotated_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotated_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43msensitive_feature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sf_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_feature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cf_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Build into cache\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_populate_results(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_disaggregated_result.py:363\u001b[0m, in \u001b[0;36mDisaggregatedResult.create\u001b[0;34m(data, annotated_functions, sensitive_feature_names, control_feature_names)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# Calculate the 'overall' values\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m control_feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     overall \u001b[38;5;241m=\u001b[39m \u001b[43mapply_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotated_functions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     temp \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39mcontrol_feature_names)\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    366\u001b[0m         apply_to_dataframe, metric_functions\u001b[38;5;241m=\u001b[39mannotated_functions\n\u001b[1;32m    367\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_disaggregated_result.py:52\u001b[0m, in \u001b[0;36mapply_to_dataframe\u001b[0;34m(data, metric_functions)\u001b[0m\n\u001b[1;32m     50\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m function_name, metric_function \u001b[38;5;129;01min\u001b[39;00m metric_functions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 52\u001b[0m     values[function_name] \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# correctly handle zero provided metrics\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_annotated_metric_function.py:106\u001b[0m, in \u001b[0;36mAnnotatedMetricFunction.__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func_arg_name, data_arg_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_argument_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Need to convert to list first in case we have 2D arrays\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     kwargs[func_arg_name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mlist\u001b[39m(df[data_arg_name]))\n\u001b[0;32m--> 106\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m, in \u001b[0;36mdemographic_parity_diff\u001b[0;34m(y_true, y_pred, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdemographic_parity_diff\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdemographic_parity_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: demographic_parity_difference() missing 1 required keyword-only argument: 'sensitive_features'"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
    "\n",
    "# Custom wrapper functions for metrics\n",
    "def demographic_parity_diff(y_true, y_pred, **kwargs):\n",
    "    return demographic_parity_difference(y_true, y_pred, **kwargs)\n",
    "\n",
    "def equalized_odds_diff(y_true, y_pred, **kwargs):\n",
    "    return equalized_odds_difference(y_true, y_pred, **kwargs)\n",
    "\n",
    "# Calculate fairness metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'demographic_parity_difference': demographic_parity_diff,\n",
    "    'equalized_odds_difference': equalized_odds_diff\n",
    "}\n",
    "\n",
    "# Ensure sensitive features match y_true\n",
    "y_true_test = y_test.reset_index(drop=True)\n",
    "sex_test = sex_test.reset_index(drop=True)\n",
    "\n",
    "metric_frame = MetricFrame(metrics=metrics, y_true=y_true_test, y_pred=y_pred, sensitive_features=sex_test)\n",
    "print(metric_frame.by_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db67bd2d-1bc6-411c-bbf0-bde3c1bef93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Income Dataset\n",
      "Accuracy: 0.8534725675451682\n",
      "Precision: 0.7584\n",
      "Recall: 0.6196078431372549\n",
      "F1 Score: 0.6820143884892087\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Column race_ White not found in DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m race_white_column \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m onehot_columns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_ White\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Ensure the column exists\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m race_white_column \u001b[38;5;129;01min\u001b[39;00m adult_data_encoded\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrace_white_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in DataFrame.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m adult_dataset \u001b[38;5;241m=\u001b[39m BinaryLabelDataset(favorable_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, unfavorable_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     75\u001b[0m                                    df\u001b[38;5;241m=\u001b[39madult_data_encoded, label_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincome\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     76\u001b[0m                                    protected_attribute_names\u001b[38;5;241m=\u001b[39m[race_white_column])\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Reweighing\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Column race_ White not found in DataFrame."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.explainers import MetricTextExplainer\n",
    "\n",
    "# Load Adult Income Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status',\n",
    "                'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', \n",
    "                'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "adult_data = pd.read_csv(url, header=None, names=column_names, na_values=' ?')\n",
    "\n",
    "# Preprocess Adult Income Dataset\n",
    "adult_data.dropna(inplace=True)\n",
    "adult_data['income'] = adult_data['income'].apply(lambda x: 1 if x == ' >50K' else 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X_adult = adult_data.drop('income', axis=1)\n",
    "y_adult = adult_data['income']\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "categorical_features = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Model pipeline\n",
    "model_adult = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Split the data\n",
    "X_train_adult, X_test_adult, y_train_adult, y_test_adult = train_test_split(X_adult, y_adult, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_adult.fit(X_train_adult, y_train_adult)\n",
    "y_pred_adult = model_adult.predict(X_test_adult)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Adult Income Dataset')\n",
    "print('Accuracy:', accuracy_score(y_test_adult, y_pred_adult))\n",
    "print('Precision:', precision_score(y_test_adult, y_pred_adult))\n",
    "print('Recall:', recall_score(y_test_adult, y_pred_adult))\n",
    "print('F1 Score:', f1_score(y_test_adult, y_pred_adult))\n",
    "\n",
    "# Fairness-aware preprocessing\n",
    "X_adult_encoded = pd.DataFrame(preprocessor.fit_transform(X_adult).toarray())\n",
    "adult_data_encoded = pd.concat([X_adult_encoded, y_adult.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Find the column name for 'race_ White'\n",
    "onehot_columns = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "race_white_column = [col for col in onehot_columns if 'race_ White' in col][0]\n",
    "\n",
    "# Ensure the column exists\n",
    "assert race_white_column in adult_data_encoded.columns, f\"Column {race_white_column} not found in DataFrame.\"\n",
    "\n",
    "adult_dataset = BinaryLabelDataset(favorable_label=1, unfavorable_label=0,\n",
    "                                   df=adult_data_encoded, label_names=['income'],\n",
    "                                   protected_attribute_names=[race_white_column])\n",
    "\n",
    "# Reweighing\n",
    "RW = Reweighing(unprivileged_groups=[{race_white_column: 0}], privileged_groups=[{race_white_column: 1}])\n",
    "adult_dataset_transf = RW.fit_transform(adult_dataset)\n",
    "\n",
    "# Split transformed data\n",
    "X_train_adult_transf, X_test_adult_transf, y_train_adult_transf, y_test_adult_transf = train_test_split(\n",
    "    adult_dataset_transf.features, adult_dataset_transf.labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on transformed data\n",
    "model_adult.fit(X_train_adult_transf, y_train_adult_transf)\n",
    "y_pred_adult_transf = model_adult.predict(X_test_adult_transf)\n",
    "\n",
    "# Evaluate the model on transformed data\n",
    "print('Transformed Adult Income Dataset')\n",
    "print('Accuracy:', accuracy_score(y_test_adult_transf, y_pred_adult_transf))\n",
    "print('Precision:', precision_score(y_test_adult_transf, y_pred_adult_transf))\n",
    "print('Recall:', recall_score(y_test_adult_transf, y_pred_adult_transf))\n",
    "print('F1 Score:', f1_score(y_test_adult_transf, y_pred_adult_transf))\n",
    "\n",
    "# Fairness metrics\n",
    "metric_transf = BinaryLabelDatasetMetric(adult_dataset_transf, \n",
    "                                         unprivileged_groups=[{race_white_column: 0}], \n",
    "                                         privileged_groups=[{race_white_column: 1}])\n",
    "explainer_transf = MetricTextExplainer(metric_transf)\n",
    "print(explainer_transf.disparate_impact())\n",
    "print(explainer_transf.statistical_parity_difference())\n",
    "\n",
    "# Load COMPAS Recidivism Dataset\n",
    "url = \"https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\"\n",
    "compas_data = pd.read_csv(url)\n",
    "\n",
    "# Preprocess COMPAS Recidivism Dataset\n",
    "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30) & \n",
    "                          (compas_data.days_b_screening_arrest >= -30) & \n",
    "                          (compas_data.is_recid != -1) & \n",
    "                          (compas_data.c_charge_degree != \"O\") & \n",
    "                          (compas_data.score_text != \"N/A\")]\n",
    "\n",
    "compas_data['recidivism'] = compas_data['two_year_recid'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Define features and target variable\n",
    "X_compas = compas_data[['age', 'sex', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
    "                        'priors_count', 'c_charge_degree']]\n",
    "y_compas = compas_data['recidivism']\n",
    "\n",
    "# Split the data\n",
    "X_train_compas, X_test_compas, y_train_compas, y_test_compas = train_test_split(X_compas, y_compas, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = ['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count']\n",
    "categorical_features = ['sex', 'race', 'c_charge_degree']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Model pipeline\n",
    "model_compas = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# Train the model\n",
    "model_compas.fit(X_train_compas, y_train_compas)\n",
    "y_pred_compas = model_compas.predict(X_test_compas)\n",
    "\n",
    "# Evaluate the model\n",
    "print('COMPAS Recidivism Dataset')\n",
    "print('Accuracy:', accuracy_score(y_test_compas, y_pred_compas))\n",
    "print('Precision:', precision_score(y_test_compas, y_pred_compas))\n",
    "print('Recall:', recall_score(y_test_compas, y_pred_compas))\n",
    "print('F1 Score:', f1_score(y_test_compas, y_pred_compas))\n",
    "\n",
    "# Fairness-aware preprocessing\n",
    "X_compas_encoded = pd.DataFrame(preprocessor.fit_transform(X_compas).toarray())\n",
    "compas_data_encoded = pd.concat([X_compas_encoded, y_compas.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# # Find the column name for 'race_ African-American'\n",
    "# onehot_columns = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "# race_black_column = [col for col in onehot_columns if 'race_ African-American'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b013adc0-c644-40f9-9705-b1a66d1f2237",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learntools.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Set up feedback system\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binder\n\u001b[1;32m      3\u001b[0m binder\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlearntools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01methics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mex4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'learntools.core'"
     ]
    }
   ],
   "source": [
    "# Set up feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.ethics.ex4 import *\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7048b204-5808-4e25-bfe9-37334b5a4d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: learntools in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (0.0.20)\n",
      "Requirement already satisfied: numpy in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from learntools) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install learntools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcf1fe-99d4-469b-ad81-af70d0afa6d8",
   "metadata": {},
   "source": [
    "# Detect Bias using Fairlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d346796-d372-4d6e-ab07-e0954e24e413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in /home/amehmood/anaconda3/envs/main_env/lib/python3.8/site-packages (from lightgbm) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8f130e-f29c-49cc-9be7-9edde80f0ef9",
   "metadata": {},
   "source": [
    "### Step 1: Load and Prepare the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a80be1d-ba9f-4992-9653-72b95fff9831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "Male      32650\n",
      "Female    16192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fairlearn.datasets import fetch_adult\n",
    "\n",
    "# Load the dataset\n",
    "data = fetch_adult(as_frame=True)\n",
    "X = pd.get_dummies(data.data)\n",
    "y_true = (data.target == '>50K') * 1\n",
    "sex = data.data['sex']\n",
    "\n",
    "# Check the distribution of the sensitive attribute\n",
    "print(sex.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c289b8-b8ab-4be8-9abe-5122e800fb6e",
   "metadata": {},
   "source": [
    "### Step 2: Train Initial Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe743f5e-1305-40aa-b024-7589f8f47fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796901658363475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88     11147\n",
      "           1       0.71      0.25      0.37      3506\n",
      "\n",
      "    accuracy                           0.80     14653\n",
      "   macro avg       0.76      0.61      0.63     14653\n",
      "weighted avg       0.78      0.80      0.76     14653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test, sex_train, sex_test = train_test_split(X, y_true, sex, test_size=0.3, random_state=0, stratify=y_true)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d64513-8884-444a-99f6-1065494a3e24",
   "metadata": {},
   "source": [
    "### Step 3: Detect Bias using Fairlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54ad5f2-f37c-44d9-bc3a-2d6135a0bc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14653, 4907]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate fairness metrics\u001b[39;00m\n\u001b[1;32m      5\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: selection_rate\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m metric_frame \u001b[38;5;241m=\u001b[39m \u001b[43mMetricFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msex_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric_frame\u001b[38;5;241m.\u001b[39moverall)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics by group:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric_frame\u001b[38;5;241m.\u001b[39mby_group)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_metric_frame.py:280\u001b[0m, in \u001b[0;36mMetricFrame.__init__\u001b[0;34m(self, metrics, y_true, y_pred, sensitive_features, control_features, sample_params, n_boot, ci_quantiles, random_state)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Create the basic results\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDisaggregatedResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotated_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotated_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43msensitive_feature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sf_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_feature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cf_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Build into cache\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_populate_results(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_disaggregated_result.py:385\u001b[0m, in \u001b[0;36mDisaggregatedResult.create\u001b[0;34m(data, annotated_functions, sensitive_feature_names, control_feature_names)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m control_feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# Note that we prepend the control feature names\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     all_grouping_names \u001b[38;5;241m=\u001b[39m control_feature_names \u001b[38;5;241m+\u001b[39m all_grouping_names\n\u001b[0;32m--> 385\u001b[0m temp \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_grouping_names\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapply_to_dataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotated_functions\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_grouping_names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# We might have missing combinations in the input, so expand to fill\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     all_classes \u001b[38;5;241m=\u001b[39m extract_unique_classes(data, all_grouping_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1341\u001b[0m, in \u001b[0;36mGroupBy.apply.<locals>.f\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(g):\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_disaggregated_result.py:52\u001b[0m, in \u001b[0;36mapply_to_dataframe\u001b[0;34m(data, metric_functions)\u001b[0m\n\u001b[1;32m     50\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m function_name, metric_function \u001b[38;5;129;01min\u001b[39;00m metric_functions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 52\u001b[0m     values[function_name] \u001b[38;5;241m=\u001b[39m \u001b[43mmetric_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# correctly handle zero provided metrics\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_annotated_metric_function.py:106\u001b[0m, in \u001b[0;36mAnnotatedMetricFunction.__call__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func_arg_name, data_arg_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_argument_mapping\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Need to convert to list first in case we have 2D arrays\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     kwargs[func_arg_name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mlist\u001b[39m(df[data_arg_name]))\n\u001b[0;32m--> 106\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate fairness metrics\u001b[39;00m\n\u001b[1;32m      5\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: accuracy_score,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision_score,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall_score,\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemographic_parity_difference\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: \u001b[43mdemographic_parity_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msex_test\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequalized_odds_difference\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m y_true, y_pred: equalized_odds_difference(y_true, y_pred, sensitive_features\u001b[38;5;241m=\u001b[39msex_test),\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselection_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: selection_rate\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     14\u001b[0m metric_frame \u001b[38;5;241m=\u001b[39m MetricFrame(metrics\u001b[38;5;241m=\u001b[39mmetrics, y_true\u001b[38;5;241m=\u001b[39my_test, y_pred\u001b[38;5;241m=\u001b[39my_pred, sensitive_features\u001b[38;5;241m=\u001b[39msex_test)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric_frame\u001b[38;5;241m.\u001b[39moverall)\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_fairness_metrics.py:45\u001b[0m, in \u001b[0;36mdemographic_parity_difference\u001b[0;34m(y_true, y_pred, sensitive_features, method, sample_weight)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdemographic_parity_difference\u001b[39m(\n\u001b[1;32m     11\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sensitive_features, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetween_groups\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the demographic parity difference.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    The demographic parity difference is defined as the difference\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m        The demographic parity difference\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     sel_rate \u001b[38;5;241m=\u001b[39m \u001b[43mMetricFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msensitive_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     result \u001b[38;5;241m=\u001b[39m sel_rate\u001b[38;5;241m.\u001b[39mdifference(method\u001b[38;5;241m=\u001b[39mmethod)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_metric_frame.py:249\u001b[0m, in \u001b[0;36mMetricFrame.__init__\u001b[0;34m(self, metrics, y_true, y_pred, sensitive_features, control_features, sample_params, n_boot, ci_quantiles, random_state)\u001b[0m\n\u001b[1;32m    246\u001b[0m annotated_funcs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_functions(metrics, sample_params, all_data)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Now, prepare the sensitive features\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m sf_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitive_feature_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitive_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sf_names \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mname_ \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sf_list]\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# Prepare the control features\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Adjust _sf_indices if needed\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/fairlearn/metrics/_metric_frame.py:976\u001b[0m, in \u001b[0;36mMetricFrame._process_features\u001b[0;34m(self, base_name, features, sample_array)\u001b[0m\n\u001b[1;32m    973\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[0;32m--> 976\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(GroupFeature(base_name, features, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n",
      "File \u001b[0;32m~/anaconda3/envs/main_env/lib/python3.8/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14653, 4907]"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference, selection_rate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Calculate fairness metrics\n",
    "metrics = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'demographic_parity_difference': lambda y_true, y_pred: demographic_parity_difference(y_true, y_pred, sensitive_features=sex_test),\n",
    "    'equalized_odds_difference': lambda y_true, y_pred: equalized_odds_difference(y_true, y_pred, sensitive_features=sex_test),\n",
    "    'selection_rate': selection_rate\n",
    "}\n",
    "\n",
    "metric_frame = MetricFrame(metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sex_test)\n",
    "print(\"Overall metrics:\", metric_frame.overall)\n",
    "print(\"Metrics by group:\", metric_frame.by_group)\n",
    "\n",
    "# Plot the metrics by group\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    title=\"Metrics by Group\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d061053d-1ffb-455a-ba27-559159e6847c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
